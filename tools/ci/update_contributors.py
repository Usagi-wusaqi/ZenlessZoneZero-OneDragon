#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›´æ–°è´¡çŒ®è€…ä¿¡æ¯è„šæœ¬
ä»å„ä¸ªæ¥æºæŠ“å–è´¡çŒ®è€…ä¿¡æ¯ï¼Œå¹¶æ›´æ–°contributors.yamlæ–‡ä»¶
"""

import urllib.request
import urllib.error
import re
import yaml
import os
import time
import json
from datetime import datetime
from typing import List, Dict, Any, Optional


def http_get(url: str, headers: Optional[dict] = None, retries: int = 5, backoff: float = 1.0) -> str:
    """
    æ‰§è¡Œå¸¦é‡è¯•å’Œè¯·æ±‚å¤´çš„HTTP GETè¯·æ±‚ï¼Œè¿”å›æ–‡æœ¬å†…å®¹
    """
    if headers is None:
        headers = {}

    req = urllib.request.Request(url, headers=headers)

    for attempt in range(1, retries + 1):
        try:
            with urllib.request.urlopen(req, timeout=15) as resp:
                # æ£€æŸ¥å“åº”å¤´ä¸­çš„é€Ÿç‡é™åˆ¶ä¿¡æ¯
                if 'X-RateLimit-Remaining' in resp.headers:
                    remaining = int(resp.headers.get('X-RateLimit-Remaining', 0))
                    reset_time = resp.headers.get('X-RateLimit-Reset', 0)

                    if remaining < 2:  # å¦‚æœå‰©ä½™è¯·æ±‚æ•°å¾ˆå°‘ï¼Œåˆ™ç­‰å¾…
                        import datetime
                        reset_timestamp = int(reset_time)
                        current_time = int(time.time())
                        wait_time = max(0, reset_timestamp - current_time)

                        if wait_time > 0:
                            print(f"æ£€æµ‹åˆ°æ¥è¿‘é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
                            time.sleep(wait_time)

                return resp.read().decode("utf-8")
        except urllib.error.HTTPError as e:
            print(f"HTTPé”™è¯¯ (å°è¯• {attempt}/{retries}): {e.code} {e.reason}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
            if e.code == 403:
                print("è­¦å‘Š: å¯èƒ½é‡åˆ°GitHub APIé€Ÿç‡é™åˆ¶")
                try:
                    error_content = e.read().decode()
                    if 'rate limit' in error_content.lower():
                        print("æç¤º: è®¾ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡å¯ä»¥æé«˜é€Ÿç‡é™åˆ¶")
                except:
                    pass  # å¿½ç•¥è¯»å–é”™è¯¯å†…å®¹çš„å¼‚å¸¸

            # å¯¹äº5xxé”™è¯¯å’Œ403é”™è¯¯è¿›è¡Œé‡è¯•ï¼ˆ403å¯èƒ½æ˜¯é€Ÿç‡é™åˆ¶ï¼‰
            if (500 <= e.code < 600 or e.code == 403) and attempt < retries:
                sleep_time = backoff * (2 ** (attempt - 1))
                print(f"ç­‰å¾… {sleep_time} ç§’åé‡è¯•...")
                time.sleep(sleep_time)
                continue
            raise
        except urllib.error.URLError as e:
            print(f"URLé”™è¯¯ (å°è¯• {attempt}/{retries}): {e.reason}")
            if attempt < retries:
                sleep_time = backoff * (2 ** (attempt - 1))
                print(f"ç­‰å¾… {sleep_time} ç§’åé‡è¯•...")
                time.sleep(sleep_time)
                continue
            raise
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯ (å°è¯• {attempt}/{retries}): {str(e)}")
            if attempt < retries:
                sleep_time = backoff * (2 ** (attempt - 1))
                print(f"ç­‰å¾… {sleep_time} ç§’åé‡è¯•...")
                time.sleep(sleep_time)
                continue
            raise
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›None
    raise Exception(f"åœ¨è¿›è¡Œäº† {retries} æ¬¡é‡è¯•åä»ç„¶æ— æ³•è·å–URL: {url}")


def fetch_github_contributors(url: str) -> List[Dict[str, Any]]:
    """
    ä»GitHubè´¡çŒ®è€…é¡µé¢æŠ“å–è´¡çŒ®è€…ä¿¡æ¯

    Args:
        url: GitHubè´¡çŒ®è€…é¡µé¢URL

    Returns:
        è´¡çŒ®è€…åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯åŒ…å«nameå’Œcontributionsçš„å­—å…¸
    """
    print(f"æ­£åœ¨ä» {url} æŠ“å–è´¡çŒ®è€…ä¿¡æ¯...")
    contributors: List[Dict[str, Any]] = []

    # æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å– GitHub token ä»¥æé«˜æˆåŠŸç‡
    token = os.environ.get("GITHUB_TOKEN")
    # ä½¿ç”¨æ›´æ ‡å‡†çš„ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) OneDragon-Contrib-Script/1.0"}
    if token:
        headers["Authorization"] = f"Bearer {token}"  # ä½¿ç”¨Bearer tokenæ ¼å¼
        headers["Accept"] = "application/vnd.github.v3+json"

    try:
        # å¦‚æœè°ƒç”¨çš„æ˜¯ graphs/contributors é¡µé¢ï¼Œå°½é‡ä½¿ç”¨ API æ›¿ä»£
        if "github.com" in url:
            # è§£æ owner/repo
            m = re.search(r"github\.com/([^/]+/[^/]+)", url)
            if m:
                owner_repo = m.group(1).rstrip("/")
                api_url = f"https://api.github.com/repos/{owner_repo}/contributors?per_page=100&page=1"

                try:
                    text = http_get(api_url, headers=headers)
                    data = json.loads(text)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
                    if isinstance(data, dict) and 'message' in data:
                        print(f"GitHub API é”™è¯¯: {data.get('message', 'Unknown error')}")
                        if 'API rate limit exceeded' in data.get('message', ''):
                            print("æç¤º: GitHub API é€Ÿç‡é™åˆ¶å·²è¾¾åˆ°ï¼Œè¯·ç¨åå†è¯•æˆ–è®¾ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡")
                        return []

                    for item in data:
                        name = item.get("login") or item.get("name") or ""
                        contributions_count = item.get("contributions")
                        contrib_str = f"{contributions_count} contributions" if contributions_count is not None else ""
                        if name:
                            contributors.append({"name": name, "contributions": contrib_str})
                    print(f"æˆåŠŸæŠ“å– {len(contributors)} ä¸ªè´¡çŒ®è€…ä¿¡æ¯ (via API)")
                    return contributors
                except Exception as api_error:
                    print(f"API è¯·æ±‚å¤±è´¥: {api_error}")
                    # å¦‚æœAPIå¤±è´¥ï¼Œå›é€€åˆ°HTMLè§£æ
                    pass

        # å›é€€ï¼šç›´æ¥æŠ“å–é¡µé¢å¹¶è§£æHTMLï¼ˆä¿æŒåŸæœ‰è§£æé€»è¾‘ï¼‰
        html_content = http_get(url, headers=headers)
        pattern = r'<a class="Link--secondary".*?>(.*?)</a>.*?<span class="text-muted text-small">([0-9,]+) contributions</span>'
        matches = re.finditer(pattern, html_content, re.DOTALL)
        for match in matches:
            name = match.group(1).strip()
            contributions = match.group(2).strip().replace(",", "")
            if name and contributions:
                contributors.append({"name": name, "contributions": f"{contributions} contributions"})

        print(f"æˆåŠŸæŠ“å– {len(contributors)} ä¸ªè´¡çŒ®è€…ä¿¡æ¯ (via HTML)")
        return contributors
    except Exception as e:
        print(f"ä»GitHubæŠ“å–è´¡çŒ®è€…ä¿¡æ¯å¤±è´¥: {e}")
        return []


def fetch_qq_channel_authors(url: str) -> List[Dict[str, Any]]:
    """
    ä»QQé¢‘é“æŠ“å–ä½œè€…ä¿¡æ¯

    Args:
        url: QQé¢‘é“URL

    Returns:
        ä½œè€…åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯åŒ…å«nameçš„å­—å…¸
    """
    print(f"æ­£åœ¨ä» {url} æŠ“å–ä½œè€…ä¿¡æ¯...")
    # ä½¿ç”¨æ›´æ ‡å‡†çš„ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 OneDragon-Contrib-Script/1.0"}
    try:
        html_content = http_get(url, headers=headers)
        authors: List[Dict[str, Any]] = []
        seen_names = set()  # ç”¨äºå»é‡
        
        # å°è¯•å¤šç§å¯èƒ½çš„æ¨¡å¼æ¥åŒ¹é…ä½œè€…
        patterns = [
            r'<h3 class="nick hover-underline".*?>(.*?)</h3>',
            r'<div class="nick".*?>(.*?)</div>',
            r'class="nickname".*?>(.*?)</a>',
            r'<p[^>]*class="[^"]*nick[^"]*"[^>]*>(.*?)</p>',
            r'<span[^>]*class="[^"]*nick[^"]*"[^>]*>(.*?)</span>',
            r'nickname["\']?\s*[:=]\s*["\']([^"\'>]+)["\']?',  # JSON-likeæ•°æ®
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, html_content, re.DOTALL | re.IGNORECASE)
            for match in matches:
                name = match.group(1).strip()
                # æ¸…ç†HTMLå®ä½“å’Œå¤šä½™çš„ç©ºç™½
                name = re.sub(r'<[^>]+>', '', name)  # ç§»é™¤ä»»ä½•å‰©ä½™çš„HTMLæ ‡ç­¾
                name = re.sub(r'&nbsp;|&#160;', ' ', name)  # æ›¿æ¢éæ–­ç©ºæ ¼
                name = re.sub(r'&[a-z]+;?', '', name)  # ç§»é™¤å…¶ä»–HTMLå®ä½“
                name = name.strip()
                
                if name and name not in seen_names and len(name) > 0 and len(name) < 50:  # è¿‡æ»¤æ‰å¤ªé•¿æˆ–å¤ªçŸ­çš„åå­—
                    seen_names.add(name)
                    authors.append({"name": name, "role": "ç¤¾åŒºä½œè€…", "contributions": "ç¤¾åŒºæ–‡ç« è´¡çŒ®"})
        
        print(f"æˆåŠŸæŠ“å– {len(authors)} ä¸ªä½œè€…ä¿¡æ¯")
        return authors
    except Exception as e:
        print(f"ä»QQé¢‘é“æŠ“å–ä½œè€…ä¿¡æ¯å¤±è´¥: {e}")
        return []


def fetch_recent_commits(url: str) -> List[Dict[str, Any]]:
    """
    ä»GitHubè·å–æœ€è¿‘çš„commitä¿¡æ¯

    Args:
        url: GitHubä»“åº“URL

    Returns:
        æœ€è¿‘10ä¸ªcommiteråˆ—è¡¨
    """
    print(f"æ­£åœ¨ä» {url} æŠ“å–æœ€è¿‘commitä¿¡æ¯...")
    token = os.environ.get("GITHUB_TOKEN")
    # ä½¿ç”¨æ›´æ ‡å‡†çš„ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) OneDragon-Contrib-Script/1.0"}
    if token:
        headers["Authorization"] = f"Bearer {token}"  # ä½¿ç”¨Bearer tokenæ ¼å¼
        headers["Accept"] = "application/vnd.github.v3+json"

    try:
        if "github.com" in url:
            m = re.search(r"github\.com/([^/]+/[^/]+)", url)
            if m:
                owner_repo = m.group(1).rstrip("/")
                api_url = f"https://api.github.com/repos/{owner_repo}/commits?per_page=10"

                try:
                    text = http_get(api_url, headers=headers)
                    commits = json.loads(text)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
                    if isinstance(commits, dict) and 'message' in commits:
                        print(f"GitHub API é”™è¯¯: {commits.get('message', 'Unknown error')}")
                        if 'API rate limit exceeded' in commits.get('message', ''):
                            print("æç¤º: GitHub API é€Ÿç‡é™åˆ¶å·²è¾¾åˆ°ï¼Œè¯·ç¨åå†è¯•æˆ–è®¾ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡")
                        return []

                    recent_contributors: List[Dict[str, Any]] = []
                    seen_authors = set()
                    for commit in commits:
                        # æœ‰æ—¶ author ä¿¡æ¯åœ¨ä¸åŒä½ç½®
                        name = None
                        if isinstance(commit, dict):
                            if commit.get("author") and isinstance(commit.get("author"), dict):
                                name = commit["author"].get("login")
                            elif not name and commit.get("commit") and commit["commit"].get("author"):
                                name = commit["commit"]["author"].get("name")
                        if name and name not in seen_authors:
                            seen_authors.add(name)
                            recent_contributors.append({"name": name, "role": "å¼€å‘è€…", "contributions": "è¿‘æœŸæäº¤"})

                    print(f"æˆåŠŸæŠ“å– {len(recent_contributors)} ä¸ªè¿‘æœŸè´¡çŒ®è€…")
                    return recent_contributors
                except Exception as api_error:
                    print(f"Commit API è¯·æ±‚å¤±è´¥: {api_error}")
                    return []

        # å›é€€ï¼šå¦‚æœAPIä¸å¯ç”¨åˆ™è¿”å›ç©ºåˆ—è¡¨
        print("æŠ“å–æœ€è¿‘commitä¿¡æ¯å¤±è´¥: æ— æ³•é€šè¿‡APIè·å¾—æ•°æ®")
        return []
    except Exception as e:
        print(f"æŠ“å–æœ€è¿‘commitä¿¡æ¯å¤±è´¥: {e}")
        return []


def update_contributors_file():
    """
    æ›´æ–°contributors.yamlæ–‡ä»¶
    """
    # å®šä¹‰å„ä¸ªæ¥æºçš„URL
    github_repo_url = "https://github.com/OneDragon-Anything/ZenlessZoneZero-OneDragon"
    github_docs_url = (
        "https://github.com/OneDragon-Anything/onedragon-anything.github.io"
    )
    qq_channel_url = "https://pd.qq.com/g/onedrag00n?subc=714508468"

    # æŠ“å–å„ä¸ªæ¥æºçš„è´¡çŒ®è€…ä¿¡æ¯
    core_contributors = fetch_github_contributors(
        f"{github_repo_url}/graphs/contributors"
    )
    recent_contributors = fetch_recent_commits(github_repo_url)
    docs_contributors = fetch_github_contributors(
        f"{github_docs_url}/graphs/contributors"
    )
    community_maintainers = fetch_qq_channel_authors(qq_channel_url)

    # è¯»å–ç°æœ‰æ–‡ä»¶å†…å®¹
    contributors_file = "contributors.yaml"
    existing_data = {}

    if os.path.exists(contributors_file):
        with open(contributors_file, "r", encoding="utf-8") as f:
            existing_data = yaml.safe_load(f)

    # æ›´æ–°è´¡çŒ®è€…ä¿¡æ¯
    contributors_data = {
        "# é¡¹ç›®è´¡çŒ®è€…ä¿¡æ¯": "",
        "# æ­¤æ–‡ä»¶åŒ…å«é¡¹ç›®çš„æ‰€æœ‰è´¡çŒ®è€…ä¿¡æ¯ï¼Œç”¨äºæ»šåŠ¨å­—å¹•æ˜¾ç¤º": "",
        "# æ›´æ–°æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "# é¡¹ç›®æ ¸å¿ƒè´¡çŒ®è€…ï¼ˆæ¥è‡ªGitHubï¼‰": "",
        "core_contributors": core_contributors[:10],  # åªä¿ç•™å‰10ä¸ªæ ¸å¿ƒè´¡çŒ®è€…
        "# è¿‘æœŸè´¡çŒ®è€…ï¼ˆæœ€å10ä¸ªcommiterï¼Œåˆå¹¶æ˜¾ç¤ºï¼‰": "",
        "recent_contributors": [{"name": "è¿‘æœŸè´¡çŒ®è€…", "members": [c["name"] for c in recent_contributors[:10]], "contributions": f"æœ€è¿‘{len(recent_contributors[:10])}æ¬¡æäº¤"}] if len(recent_contributors) >= 1 else [],  # å°†è¿‘æœŸè´¡çŒ®è€…åˆå¹¶ä¸ºä¸€ä¸ªæ¡ç›®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©º
        "# æ–‡æ¡£ç»„è´¡çŒ®è€…ï¼ˆæ¥è‡ªå®˜ç½‘/å®˜æ–¹æ–‡æ¡£ï¼‰": "",
        "documentation_contributors": docs_contributors[:10],  # åªä¿ç•™å‰10ä¸ªæ–‡æ¡£è´¡çŒ®è€…
        "# ç¤¾åŒºç»´æŠ¤è€…ï¼ˆæ¥è‡ªQQé¢‘é“ï¼Œåˆå¹¶æ˜¾ç¤ºï¼‰": "",
        "community_maintainers": [{"name": "ç¤¾åŒºç»´æŠ¤è€…", "members": [c["name"] for c in community_maintainers[:50]], "contributions": f"QQé¢‘é“{len(community_maintainers[:50])}åä½œè€…"}] if len(community_maintainers) >= 1 else [],  # å°†ç¤¾åŒºç»´æŠ¤è€…åˆå¹¶ä¸ºä¸€ä¸ªæ¡ç›®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºï¼Œæœ€å¤šæ˜¾ç¤º20ä¸ª
        "# å…¶ä»–è´¡çŒ®è€…ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰": "",
        "other_contributors": existing_data.get(
            "other_contributors", [
                {"name": "æ¨¡èŒƒå¥½å¸‚æ°‘ğŸ…", "members": ["(#_#)", "Theresa Apocalypse", "YU4106", "é¡¾åŒ—ç„¶"]},
                {"name": "æµ‹è¯•å…ˆé”‹é˜ŸğŸš€", "members": ["è‡ªç„¶"]},
                {"name": "ç©ºæ´è§‚å¯Ÿå‘˜ğŸ“š", "members": ["ä¹Œè¨å¥‡", "è‡ªç„¶", "çº¢è±†æ³¥", "èŒ¶å³’"]}
            ]
        ),  # ä¿ç•™æ‰‹åŠ¨æ·»åŠ çš„è´¡çŒ®è€…ï¼Œæä¾›é»˜è®¤æ¨¡æ¿ï¼ŒåŸºäºç°æœ‰æ ¼å¼
    }

    # å†™å…¥æ›´æ–°åçš„æ–‡ä»¶
    with open(contributors_file, "w", encoding="utf-8") as f:
        yaml.dump(
            contributors_data,
            f,
            default_flow_style=False,
            allow_unicode=True,
            sort_keys=False,
        )

    print(f"æˆåŠŸæ›´æ–° {contributors_file} æ–‡ä»¶")
    print(f"æ ¸å¿ƒè´¡çŒ®è€…: {len(contributors_data['core_contributors'])}")
    print(f"è¿‘æœŸè´¡çŒ®è€…: {len(contributors_data['recent_contributors'])}")
    print(f"æ–‡æ¡£è´¡çŒ®è€…: {len(contributors_data['documentation_contributors'])}")
    print(f"ç¤¾åŒºç»´æŠ¤è€…: {len(contributors_data['community_maintainers'])}")
    print(f"å…¶ä»–è´¡çŒ®è€…: {len(contributors_data['other_contributors'])}")


if __name__ == "__main__":
    print("å¼€å§‹æ›´æ–°è´¡çŒ®è€…ä¿¡æ¯...")
    update_contributors_file()
    print("è´¡çŒ®è€…ä¿¡æ¯æ›´æ–°å®Œæˆï¼")
